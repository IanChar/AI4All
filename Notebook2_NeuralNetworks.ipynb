{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Adapted from:\n",
    "* https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Neural Networks?\n",
    "\n",
    "Neural networks have become an extremely popular tool in AI and machine learning. At its core, neural networks are simply a series of mathematical operations applied to some given inputs. The term \"neural network\" comes from the fact that each one of these mathematical operations can be thought of as a neuron firing in a brain.\n",
    "\n",
    "### Neurons\n",
    "\n",
    "Following this brain analogy, we will first talk about the basic building block on a neural network: the \"neuron\". A neuron takes a multitude of different numbers, combines these inputs, then spits out a single number. A visualization of a neuron is shown below.\n",
    "\n",
    "<img src=\"img/neuron.png\">\n",
    "\n",
    "There are three steps to computing the final output for a neuron:\n",
    "\n",
    "1. Multiply the inputs by weights (this is represented by the red blocks in the picture). For example, in the picture above there are two inputs $x_1$ and $x_2$. The neuron keeps track of corresponding weights $w_1$ and $w_2$, and in the first step we multiply $x_1$ by $w_1$ and $x_2$ by $w_2$.\n",
    "\n",
    "2. Add the weighted inputs and bias together (green block). Along with the weights, the neuron keeps track of a bias term we will refer to as $b$. The second step is then to compute $w_1 * x_1 + w_2 * x_2 + b$.\n",
    "\n",
    "3. Apply an _activation_ function (yellow block). In this last step, we can apply any arbitrary function $f$. That is, we compute $f(w_1 * x_1 + w_2 * x_2 + b)$. There are several popular choices of functions that we will discuss later.\n",
    "\n",
    "### Playing around with Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we will consider a neuron that takes a single input. The activation function that we will consider is the step function $f$ defined to be,\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{cases}\n",
    "1 & x \\geq 0 \\\\\n",
    "0 & x < 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In other words, $f(x)$ is 1 if $x$ is greater than or equal to $0$ and is $0$ if $x$ is negative. Suppose that we wish to design our neuron so that it outputs 1 if $x_1 \\leq -2$ and $0$ if $x_1 > -2$. Fill in the missing weight and bias that achieves this neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 1.000000\t Code Output: 1.000000\t Expected: 0.000000\tIncorrect :(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the correct w_1 and b!\n",
    "w_1 = 0\n",
    "b = 0\n",
    "\n",
    "def neuron(x_1):\n",
    "    # Step 1: Multiply weight.\n",
    "    step1 = w_1 * x_1\n",
    "    # Step 2: Add bias.\n",
    "    step2 = step1 + b\n",
    "    # Step 3: Apply activation function.\n",
    "    step3 = activation(step2)\n",
    "    return step3\n",
    "\n",
    "def activation(z):\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def tester(x_1, correct_val):\n",
    "    \"\"\"Helper function to check your work.\n",
    "    Args:\n",
    "        x_1: Input to the neuron.\n",
    "        correct_val: What the correct value should be.\n",
    "    \"\"\"\n",
    "    output = neuron(x_1)\n",
    "    print 'Input: %f\\t Code Output: %f\\t Expected: %f\\t' % (x_1, output, correct_val),\n",
    "    if correct_val == output:\n",
    "        print 'Correct!'\n",
    "    else:\n",
    "        print 'Incorrect :('\n",
    "    \n",
    "# TODO: Write tests to check your weight and bias. We have provided one for you.\n",
    "tester(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that we want to create a neuron that encodes the AND function for three variables. That is, we have inputs $x_1$, $x_2$, $x_3$, all of which can either be $0$ or $1$, and we want the neuron to output $1$ only if all of theses inputs are $1$. Code this neurons and find the appropriate weights and bias below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the correct w_1, w_2, w_3, and b!\n",
    "w_1 = 0\n",
    "w_2 = 0\n",
    "w_3 = 0\n",
    "b = 0\n",
    "\n",
    "def neuron(x_1, x_2, x_3):\n",
    "    # TODO: Code the neuron!\n",
    "    # Step 1: Multiply by weights.\n",
    "    # Step 2: Add weighted inputs and bias together.\n",
    "    # Step 3: Apply activation function.\n",
    "    pass\n",
    "\n",
    "def activation(z):\n",
    "    if z >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def tester(x_1, x_2, x_3, correct_val):\n",
    "    \"\"\"Helper function to check your work.\n",
    "    Args:\n",
    "        x_1: Input to the neuron.\n",
    "        correct_val: What the correct value should be.\n",
    "    \"\"\"\n",
    "    output = neuron(x_1)\n",
    "    print 'Input: %f\\t Code Output: %f\\t Expected: %f\\t' % (x_1, output, correct_val),\n",
    "    if correct_val == output:\n",
    "        print 'Correct!'\n",
    "    else:\n",
    "        print 'Incorrect :('\n",
    "\n",
    "tester(1, 1, 1, 1)\n",
    "tester(1, 1, 0, 0)\n",
    "tester(1, 0, 1, 0)\n",
    "tester(0, 1, 1, 0)\n",
    "tester(0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing Neurons Together\n",
    "\n",
    "Now that we understand a bit about neurons, a neural network is simply multiple neurons joined together. A pictoral example of a neural network is shown below.\n",
    "\n",
    "<img src=\"img/simple_nn.png\">\n",
    "\n",
    "Here the two white circles show two inputs $x_1$ and $x_2$. These inputs are both fed into two separate neurons, $h_1$ and $h_2$. The results from each of the neurons are then fed into a final neuron, $o_1$. Let's try coding this example neural network! Each of the neurons have been coded below. Use these implementations to create the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 Test Cases Correct.\n"
     ]
    }
   ],
   "source": [
    "def neural_net(x_1, x_2):\n",
    "    # TODO: Implement the neural network. The output of this function should be the output of the neural network.\n",
    "    pass\n",
    "\n",
    "def neuron_h1(x_1, x_2):\n",
    "    w_1 = 3\n",
    "    w_2 = 1\n",
    "    b = -2\n",
    "    return activation(w_1 * x_1 + w_2 * x_2 + b)\n",
    "\n",
    "def neuron_h2(x_1, x_2):\n",
    "    w_1 = 0\n",
    "    w_2 = 3\n",
    "    b = 1\n",
    "    return activation(w_1 * x_1 + w_2 * x_2 + b)\n",
    "\n",
    "def neuron_o1(h_1, h_2):\n",
    "    w_1 = -5\n",
    "    w_2 = 3\n",
    "    b = 1\n",
    "    return activation(w_1 * h_1 + w_2 * h_2 + b)\n",
    "\n",
    "def activation(z):\n",
    "    # Here we will use the \"sigmoid\" function for our activation.\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "num_correct = 3\n",
    "if neural_net(1, 1) != 0.38747367270010746:\n",
    "    num_correct -= 1\n",
    "if neural_net(3, -1) != 0.025830530969362966:\n",
    "    num_correct -= 1\n",
    "if neural_net(2, 0) != 0.15227177022746463:\n",
    "    num_correct -= 1\n",
    "print '%d/3 Test Cases Correct.' % num_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Neural Networks with Images\n",
    "\n",
    "Relating this back to our self-driving car application, we would like to use neural networks to recognize different objects while driving. In particular, suppose that we want to create a neural network that will recognize three different types of signs: stop signs, yield signs, and pedestrian signs. The input for the neural network will be the pixel values of the image of the sign we want to classify. The final layer of the neural network, i.e. the \"output\" layer, contains three neurons. Each corresponds to one of the sign types and outputs the probability that the image contains that sign type. \n",
    "\n",
    "### Convolution Layer\n",
    "\n",
    "When dealing with images, one typically uses a Convolutional Neural Network (CNN). This is a neural network that has a layer devoted to convolutions. These layers apply convolutions in the same way that we saw in the last notebook; however, for every convolusion layer, we may apply multiple kernels to the inputs. For example, if we pass in 32x32 image to a convolution layer with 3 different kernels of size 5x5, the output with be 3x28x28 different values. (THIS SECTION COULD USE SOME WORK BUT WILL WAIT UNTIL FIRST NOTEBOOK IS DONE).\n",
    "\n",
    "### Max Pooling Layer\n",
    "\n",
    "Another special type of layer that is typically used in conjunction with convolution layers is the max pooling layer. Doing max pooling operates similarly to convolution in that there is a window that slides across the image. However, rather than taking a weighted sum of all values in the window, we simply take the largest value in the window. (FIND AN EXAMPLE ONLINE WITH A PICTURE).\n",
    "\n",
    "### Coding a CNN\n",
    "\n",
    "ONCE I KNOW WHAT IS DONE IN FIRST NOTEBOOK EXERCISE WILL BE EASIER TO MAKE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
